# implement direct preference optimization for better model inference 
import trl
from trl import DPOTrainer,DPOConfig
